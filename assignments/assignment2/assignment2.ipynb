{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis and Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "Required installations:\n",
    "* Python 3\n",
    "* Pip\n",
    "\n",
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1.1 Sentiment Analysis\n",
    "\n",
    "Given the following short movie reviews and a document D = fast, couple, shoot,\n",
    "fly. Write a python implementation (from scratch!) that compute the most likely\n",
    "class for D. Assume a naive Bayes classifier and use add-1 smoothing for the likelihoods. Each review is labeled with a genre, either comedy or action."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "class Sentiment_Naive_Bayes_Classifier:\n",
    "    \n",
    "    # Initialize dicitonaries and values to\n",
    "    # keep track of probabilities\n",
    "    def __init__(self):\n",
    "        self.label_probabilities = {}\n",
    "        self.word_as_label_probabilities = {}\n",
    "        self.vocabulary = []\n",
    "        self.total_words = 0\n",
    "        self.total_reviews = 0\n",
    "    \n",
    "    # method that increments every occurence of\n",
    "    # an entry into a given dictionary\n",
    "    def add_probability(self, p, dictionary):\n",
    "        if p in dictionary:\n",
    "            dictionary[p] += 1\n",
    "        else:\n",
    "            dictionary[p] = 1\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        for words in data:\n",
    "            self.vocabulary.extend(words)\n",
    "        \n",
    "        # Removes duplicates from the vocabulary\n",
    "        self.vocabulary = set(self.vocabulary)\n",
    "        self.total_words = len(self.vocabulary)\n",
    "        self.total_reviews = len(data)\n",
    "        \n",
    "        for words, label in zip(data, labels):\n",
    "            for word in set(words):\n",
    "                self.add_probability(\n",
    "                    (word, label), self.word_as_label_probabilities)\n",
    "            \n",
    "            self.add_probability(label, self.label_probabilities)\n",
    "            \n",
    "    # calculates probability that a singe word results in a label\n",
    "    # with add-one smoothing\n",
    "    def label_laplace_probability(self, word, label, p_label):\n",
    "        word_label_frequency = (self.word_as_label_probabilities[(word, label)]\n",
    "                           if (word, label) in self.word_as_label_probabilities else 0)\n",
    "        return (word_label_frequency + 1) / (p_label + self.total_words)\n",
    "        \n",
    "    \n",
    "    def predict(self, d):\n",
    "        predicted_probabilities = {}\n",
    "        for label in self.label_probabilities:\n",
    "            probability = self.label_probabilities[label]\n",
    "            p_label = probability / self.total_reviews\n",
    "            for word in d:\n",
    "                if word in self.vocabulary:\n",
    "                    # multiplies the probability that each word from the vocabulary\n",
    "                    # in the \n",
    "                    p_label *= self.label_laplace_probability(word, label, probability)\n",
    "                    \n",
    "            predicted_probabilities[label] = p_label\n",
    "            \n",
    "        predicted_label = max(predicted_probabilities, key=predicted_probabilities.get)\n",
    "        \n",
    "        return (predicted_label, predicted_probabilities[predicted_label])\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "d = \"fast couple shoot fly\".split()\n",
    "\n",
    "data = [(\"fun couple love love\".split(), \"comedy\"),\n",
    "        (\"fast furious shoot\".split(), \"action\"),\n",
    "        (\"couple fly fast fun fun\".split(), \"comedy\"),\n",
    "        (\"furious shoot shoot fun\".split(), \"action\"),\n",
    "        (\"fly fast shoot love\".split(), \"action\")]\n",
    "\n",
    "snbc = Sentiment_Naive_Bayes_Classifier()\n",
    "snbc.fit([review for review, label in data], [label for review, label in data])\n",
    "print(snbc.predict(d))\n",
    "\n",
    "dd = \"predictable with no fun\".split()\n",
    "\n",
    "datadata = [(\"just plain boring\".split(), \"-\"),\n",
    "        (\"entirely predictable and lacks energy\".split(), \"-\"),\n",
    "        (\"no surprises and very few laughs\".split(), \"-\"),\n",
    "        (\"very powerful\".split(), \"+\"),\n",
    "        (\"the most fun film of the summer\".split(), \"+\")]\n",
    "\n",
    "snbc = Sentiment_Naive_Bayes_Classifier()\n",
    "snbc.fit([review for review, label in datadata], [label for review, label in datadata])\n",
    "print(snbc.predict(dd))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('action', 0.00144)\n",
      "('-', 0.00019725486972959643)\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1.2 Logistic Regression\n",
    "\n",
    "* Create an implementation (from scratch!) of the Stochastic Gradient Descent Algorithm in Figure 5.5 (Page 86) of the reference book “Speech and Language Processing”.\n",
    "\n",
    "* Note: There are some implementations online. You can use them as a reference but you should try to modify the implementation and show in your report that you understand every step. Also, if you use an implementation online as a reference include in your report which reference you used. Include in your report an example run in the style of the Example in Section 5.4.3 (Page 87) of the reference book."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "class Logistic_Regressor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = [0]\n",
    "        self.b = 0\n",
    "        \n",
    "    def update_weights_bias(self, new_w, new_b):\n",
    "        self.w = new_w\n",
    "        self.b = new_b\n",
    "    \n",
    "    def predict(self, x):\n",
    "        product = []\n",
    "        for x1, w1 in zip(x, self.w):\n",
    "            product.append(x1 * w1)\n",
    "        return 1 / (1 + math.exp(-(sum(product) + self.b)))\n",
    "    \n",
    "    def cross_entropy(self, y_pred, y):\n",
    "        return -y * math.log(y_pred) + (1 - y) * math.log(y_pred)\n",
    "    \n",
    "    def gradient(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        loss = y_pred - y\n",
    "        gradients = [x[i] * loss for i in range(len(x))]\n",
    "        return gradients, loss\n",
    "    \n",
    "    def fit(self, data, labels, alpha):\n",
    "        for x, y in zip(data, labels):\n",
    "            gradients, loss = self.gradient(x, y)\n",
    "            new_w = [self.w[i] - alpha * gradients[i] for i in range(len(self.w))]\n",
    "            new_b = self.b - alpha + loss\n",
    "            self.update_weights_bias(new_w, new_b)\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# Example values\n",
    "y = 1\n",
    "x = [3, 2]\n",
    "alpha = 0.1\n",
    "\n",
    "lg = Logistic_Regressor()\n",
    "\n",
    "print(lg.predict(x))\n",
    "\n",
    "for i in range(50):\n",
    "    lg.fit([x], [y], alpha)\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(lg.predict(x))\n",
    "        print(\"weights:\", lg.w, \"bias:\", lg.b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5\n",
      "0.15917487669809918\n",
      "weights: [1.9931407442399747] bias: -7.6438024807999145\n",
      "0.027101855634289837\n",
      "weights: [4.74203158657605] bias: -17.8067719552535\n",
      "0.003805322952055705\n",
      "weights: [7.702625501856081] bias: -28.675418339520288\n",
      "0.0005176348921757234\n",
      "weights: [10.69716791001136] bias: -39.65722636670457\n",
      "7.01029450476619e-05\n",
      "weights: [13.696426941934813] bias: -50.654756473116095\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}